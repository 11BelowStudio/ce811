{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Training Neural Networks with Keras\n",
    "## And universal function approximation\n",
    "## Part of CE811, University of Essex, 2020\n",
    "\n",
    "### Dr Michael Fairbank, University of Essex, UK\n",
    "\n",
    "- Email: m.fairbank@essex.ac.uk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A simple 1D function\n",
    "\n",
    "- First build some datapoints that represent a simple 1D function, for the sake of a learning example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dataset for a simple regression problem (1 input 1 output):\n",
    "x_train=np.linspace(-2,2,100).astype(np.float32).reshape(100,1)\n",
    "y_train=(np.sin(x_train*math.pi)*0.3+x_train+-2).astype(np.float32).reshape(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (100, 1) [[-2.       ]\n",
      " [-1.9595959]\n",
      " [-1.919192 ]\n",
      " [-1.8787879]\n",
      " [-1.8383838]\n",
      " [-1.7979798]\n",
      " [-1.7575758]\n",
      " [-1.7171717]\n",
      " [-1.6767677]\n",
      " [-1.6363636]]\n",
      "y_train (100, 1) [[-4.       ]\n",
      " [-3.9216182]\n",
      " [-3.8438475]\n",
      " [-3.7672892]\n",
      " [-3.692525 ]\n",
      " [-3.6201077]\n",
      " [-3.5505521]\n",
      " [-3.4843278]\n",
      " [-3.4218502]\n",
      " [-3.363474 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\",x_train.shape, x_train[0:10])\n",
    "print(\"y_train\",y_train.shape, y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f95780949a0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show training set\n",
    "plt.plot(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Build a neural-network model capable of learning this function, from the datapoints\n",
    "- Use Keras to build a 3-layer feed-forward network (i.e. with 2 hidden layers).\n",
    "<img src=\"./images/ffnn_3layers.svg\" alt=\"3-layer FFNN\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define Sequential model with 3 layers\n",
    "model = keras.Sequential(name=\"my_neural_network\")\n",
    "layer1=layers.Dense(10, activation=\"tanh\", input_shape=(1,))\n",
    "model.add(layer1)\n",
    "layer2=layers.Dense(10, activation=\"tanh\")\n",
    "model.add(layer2)\n",
    "layer3=layers.Dense(1)\n",
    "model.add(layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_neural_network\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Understanding the model architecture\n",
    "\n",
    "- The above model print out shows us this is a 3-layer neural network.  \n",
    "\n",
    "- The \"Output Shape\" shows us how many outputs each layer has.  The first dimension is the batch size (which is flexible, hence \"None\"), and the second dimension is the number of outputs for that layer.\n",
    "\n",
    "- We can see from the final layer's output shape how many outputs this network has.\n",
    "\n",
    "- We can see from line 7 of the code how many inputs this network has.\n",
    "\n",
    "**Questions:** \n",
    "\n",
    "1. How many inputs and how many outputs does this neural network have?  **Answer**:\n",
    "2. Why do all of the output shapes start with \"None\"?  **Answer**:\n",
    "3. What is the \"rank\" of all of the output shapes?  **Answer**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Understanding model layers\n",
    "\n",
    "- In this network layer1 and layer2 are called \"hidden layers\", because they are only used for the internal calculation of the network output.\n",
    "\n",
    "- Each layer is parameterised by one or more tensors.  Tensors are just multidimensional arrays of numbers, e.g. a matrix or a vector.\n",
    "    - E.g. a matrix of shape $5 \\times 5$ is a rank-2 tensor of shape=(5,5)\n",
    "\n",
    "- For each Dense layer, there is one weights matrix and one bias vector.  These can be seen below.  \n",
    "\n",
    "- They are initially created with random values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1 weights [<tf.Variable 'dense/kernel:0' shape=(1, 10) dtype=float32, numpy=\n",
      "array([[ 0.41742057,  0.0942719 ,  0.37613028, -0.03856498, -0.384623  ,\n",
      "        -0.35715654,  0.13074309,  0.45161003,  0.18883032,  0.66952044]],\n",
      "      dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(\"layer1 weights\",layer1.trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Question:\n",
    "\n",
    "1. How many parameters in W and b are there for the first layer? **Answer:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer2 weights [<tf.Variable 'dense_1/kernel:0' shape=(10, 10) dtype=float32, numpy=\n",
      "array([[-0.21779642,  0.2891119 ,  0.48108017, -0.18359745, -0.45352882,\n",
      "         0.37127495, -0.52843744, -0.53009945, -0.36978608, -0.4600715 ],\n",
      "       [ 0.4373513 , -0.12481409, -0.42145985, -0.36179   ,  0.13139886,\n",
      "         0.0638091 ,  0.5008149 , -0.3921352 , -0.01387179, -0.04677099],\n",
      "       [ 0.47210646, -0.06752574, -0.3003423 , -0.10881665,  0.3131482 ,\n",
      "         0.22569168,  0.03907496, -0.49069148,  0.03982872,  0.37647086],\n",
      "       [-0.17339751, -0.30422935, -0.06199682, -0.41487473,  0.35192454,\n",
      "        -0.26363567, -0.40562147,  0.40462363,  0.09979177, -0.05588415],\n",
      "       [ 0.41920578,  0.22364068, -0.4256137 , -0.39103657,  0.5083028 ,\n",
      "         0.32568485, -0.21932036,  0.22510618,  0.23135394,  0.4970138 ],\n",
      "       [-0.09095219, -0.33222854, -0.32401556, -0.44280317,  0.34680718,\n",
      "         0.12376416,  0.0872097 ,  0.4076423 , -0.41173607, -0.11515221],\n",
      "       [-0.38450497, -0.12407342,  0.30873328, -0.02903396, -0.26756242,\n",
      "         0.29528767,  0.2116071 ,  0.14083987, -0.17949241, -0.45852184],\n",
      "       [-0.21933734, -0.33717757,  0.46800315, -0.34405193, -0.09308806,\n",
      "         0.360601  ,  0.5230044 , -0.09841055, -0.23900741, -0.4017169 ],\n",
      "       [-0.00380832, -0.54335093,  0.409271  , -0.09272909, -0.44841203,\n",
      "         0.4122975 ,  0.18832755,  0.00400382,  0.09695935,  0.00749922],\n",
      "       [ 0.03644365, -0.03694183, -0.27157757, -0.30238557, -0.30246383,\n",
      "        -0.22422495,  0.40906727,  0.15180832,  0.35376292, -0.27268848]],\n",
      "      dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(\"layer2 weights\",layer2.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer3 weights [<tf.Variable 'dense_2/kernel:0' shape=(10, 1) dtype=float32, numpy=\n",
      "array([[ 0.06043935],\n",
      "       [-0.38652188],\n",
      "       [ 0.19531143],\n",
      "       [ 0.05377668],\n",
      "       [-0.08651119],\n",
      "       [ 0.5629079 ],\n",
      "       [ 0.5103082 ],\n",
      "       [ 0.24011737],\n",
      "       [-0.4563308 ],\n",
      "       [ 0.10647345]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(\"layer3 weights\",layer3.trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Questions:**\n",
    "\n",
    "1. How many parameters in W and b are there for the second layer?  **Answer**:\n",
    "\n",
    "2. Do these match what the model printout said (on previous slide) **Answer**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Each layer acts as a callable function, and the whole model we have created acts as a callable function.\n",
    "\n",
    "- Layer1 has a weights matrix W (with shape \\[1,10\\]) and a bias vector b (with shape \\[10\\]).  It computes its output $y$ for an input $x$ by $y=tanh(xW+b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.8284952  -0.3508217   0.983407   -0.99176884 -0.55092657  0.78563935\n",
      "   0.8695636   0.9938032  -0.79578537  0.9920649 ]], shape=(1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Try putting a single input into the layer 1\n",
    "print(layer1(np.array([[4]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can you verify that this matches $y=tanh(xW+b)$?  \n",
    "- **Do this**: Fill in the missing line of code below to help you, and check you get the same output as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.1833184  -0.36638045  2.391794   -2.7444215  -0.6197107   1.0599358\n",
      "   1.3312871   2.8868768  -1.0870131   2.7628186 ]], shape=(1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x=tf.constant([[4.0]])\n",
    "W=layer1.trainable_weights[0] # This is the weight matrix of shape [1,10]\n",
    "b=layer1.trainable_weights[1] # This is the bias vector of shape [10]\n",
    "print(tf.matmul(x,W))  # TODO fix this line using the tensorflow functions tf.tanh(A) and tf.matmul(A,B) and the tf.add(A,B) functions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that in the final add in the above code, tensorflow used [\"broadcasting\"](https://numpy.org/devdocs/user/theory.broadcasting.html) to allow it to add a rank-2 tensor (a 2d array) to a rank-1 tensor (a 1d array)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The whole network acts as a function too.  It just puts the input into the first layer, and then the output of that into the next layer, and so on.\n",
    "\n",
    "\n",
    "**Questions:** \n",
    "\n",
    "1. If the $k$th layer can be written as a function $y=tanh(x.Wk+bk)$, then how could we write the whole network as a single mathematical function?  **Answer:**  (Enter in markdown here):\n",
    "\n",
    "2. Why do we need the tanh functions after every layer?  What would happen if we removed them?  **Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The neural network expects its input to be a rank-2 tensor (i.e. a matrix)\n",
    "- Each row of that matrix corresponds to a different input vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.2342509]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Try putting a single input into the whole network\n",
    "print(model(np.array([[4]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.23425087]\n",
      " [ 0.07320121]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Try putting a \"batch\" of 2 input vectors through the network\n",
    "print(model(np.array([[4],[2]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Notice how even though the model function accepts 1 input, it can process two 1d-vector inputs at the same time.  They are processed independently of each other - we see we get the same output now when we push \"4\" though the model as when we pushed \"4\" though on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vectors [[-2.       ]\n",
      " [-1.9595959]\n",
      " [-1.919192 ]\n",
      " [-1.8787879]\n",
      " [-1.8383838]\n",
      " [-1.7979798]\n",
      " [-1.7575758]\n",
      " [-1.7171717]\n",
      " [-1.6767677]\n",
      " [-1.6363636]]\n",
      "output vectors tf.Tensor(\n",
      "[[-0.07320121]\n",
      " [-0.08029761]\n",
      " [-0.08731581]\n",
      " [-0.09424214]\n",
      " [-0.10106359]\n",
      " [-0.10776543]\n",
      " [-0.11433295]\n",
      " [-0.12075051]\n",
      " [-0.12700114]\n",
      " [-0.13306844]], shape=(10, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Let's put a whole \"batch\" of x values through:\n",
    "print(\"input vectors\", x_train[0:10,:])\n",
    "print(\"output vectors\", model(np.array(x_train[0:10].reshape(10,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f34d839bcd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot the model's current behaviour:\n",
    "plt.plot(x_train, y_train, label = \"targets\")\n",
    "plt.plot(x_train, model(x_train).numpy(),label=\"model output\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The above graph shows the neural network is not doing what we want it to yet\n",
    "    - because we've just build our network with entirely random weights.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training the neural network\n",
    "\n",
    "So next we'll \"train\" the network, i.e. change the values of its weights so that its outputs match the target curve.  Note, that by the universal function approximation theorem for neural networks, if we have enough weights and hidden layers, then we can in theory learn any function to arbitrary accuracy.  \n",
    "\n",
    "There is no closed-form solution to this \"training\" problem, so we need to use an iterative numerical method.\n",
    "\n",
    "First we define a loss function which we want to minimise with respect to all of the trainable variables in the neural network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.01),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.MeanSquaredError()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next we run the iterative procedure.  Here we say we're going to run a full pass through the training set (all of the elements of x_train), 1000 times..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9537 - mean_squared_error: 4.9537\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4679 - mean_squared_error: 4.4679\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0394 - mean_squared_error: 4.0394\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6667 - mean_squared_error: 3.6667\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3450 - mean_squared_error: 3.3450\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0678 - mean_squared_error: 3.0678\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8270 - mean_squared_error: 2.8270\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6128 - mean_squared_error: 2.6128\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4149 - mean_squared_error: 2.4149\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2232 - mean_squared_error: 2.2232\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0299 - mean_squared_error: 2.0299\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8306 - mean_squared_error: 1.8306\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6238 - mean_squared_error: 1.6238\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4110 - mean_squared_error: 1.4110\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1958 - mean_squared_error: 1.1958\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9834 - mean_squared_error: 0.9834\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7801 - mean_squared_error: 0.7801\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5928 - mean_squared_error: 0.5928\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4286 - mean_squared_error: 0.4286\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2937 - mean_squared_error: 0.2937\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1935 - mean_squared_error: 0.1935\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1307 - mean_squared_error: 0.1307\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1049 - mean_squared_error: 0.1049\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1113 - mean_squared_error: 0.1113\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1414 - mean_squared_error: 0.1414\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1837 - mean_squared_error: 0.1837\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2265 - mean_squared_error: 0.2265\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2606 - mean_squared_error: 0.2606\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2799 - mean_squared_error: 0.2799\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2829 - mean_squared_error: 0.2829\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2713 - mean_squared_error: 0.2713\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2490 - mean_squared_error: 0.2490\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2208 - mean_squared_error: 0.2208\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1909 - mean_squared_error: 0.1909\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1627 - mean_squared_error: 0.1627\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1382 - mean_squared_error: 0.1382\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1186 - mean_squared_error: 0.1186\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1039 - mean_squared_error: 0.1039\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0938 - mean_squared_error: 0.0938\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0879 - mean_squared_error: 0.0879\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0855 - mean_squared_error: 0.0855\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0859 - mean_squared_error: 0.0859\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0882 - mean_squared_error: 0.0882\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0918 - mean_squared_error: 0.0918\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0957 - mean_squared_error: 0.0957\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0992 - mean_squared_error: 0.0992\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1017 - mean_squared_error: 0.1017\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1027 - mean_squared_error: 0.1027\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1019 - mean_squared_error: 0.1019\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0995 - mean_squared_error: 0.0995\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0955 - mean_squared_error: 0.0955\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0906 - mean_squared_error: 0.0906\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0852 - mean_squared_error: 0.0852\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0798 - mean_squared_error: 0.0798\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0750 - mean_squared_error: 0.0750\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0711 - mean_squared_error: 0.0711\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0684 - mean_squared_error: 0.0684\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0668 - mean_squared_error: 0.0668\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0661 - mean_squared_error: 0.0661\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0662 - mean_squared_error: 0.0662\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0668 - mean_squared_error: 0.0668\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0674 - mean_squared_error: 0.0674\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0679 - mean_squared_error: 0.0679\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0680 - mean_squared_error: 0.0680\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0677 - mean_squared_error: 0.0677\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0670 - mean_squared_error: 0.0670\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0660 - mean_squared_error: 0.0660\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0648 - mean_squared_error: 0.0648\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0636 - mean_squared_error: 0.0636\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0623 - mean_squared_error: 0.0623\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0611 - mean_squared_error: 0.0611\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0601 - mean_squared_error: 0.0601\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0593 - mean_squared_error: 0.0593\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0586 - mean_squared_error: 0.0586\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0581 - mean_squared_error: 0.0581\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0577 - mean_squared_error: 0.0577\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0574 - mean_squared_error: 0.0574\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0571 - mean_squared_error: 0.0571\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0569 - mean_squared_error: 0.0569\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0566 - mean_squared_error: 0.0566\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0564 - mean_squared_error: 0.0564\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0560 - mean_squared_error: 0.0560\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0557 - mean_squared_error: 0.0557\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0552 - mean_squared_error: 0.0552\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0547 - mean_squared_error: 0.0547\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0542 - mean_squared_error: 0.0542\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0537 - mean_squared_error: 0.0537\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0532 - mean_squared_error: 0.0532\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0528 - mean_squared_error: 0.0528\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0524 - mean_squared_error: 0.0524\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0520 - mean_squared_error: 0.0520\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0518 - mean_squared_error: 0.0518\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0515 - mean_squared_error: 0.0515\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0512 - mean_squared_error: 0.0512\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0510 - mean_squared_error: 0.0510\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0507 - mean_squared_error: 0.0507\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0505 - mean_squared_error: 0.0505\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0501 - mean_squared_error: 0.0501\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0498 - mean_squared_error: 0.0498\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0495 - mean_squared_error: 0.0495\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0492 - mean_squared_error: 0.0492\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0489 - mean_squared_error: 0.0489\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0486 - mean_squared_error: 0.0486\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0483 - mean_squared_error: 0.0483\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0480 - mean_squared_error: 0.0480\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0478 - mean_squared_error: 0.0478\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0475 - mean_squared_error: 0.0475\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0473 - mean_squared_error: 0.0473\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0470 - mean_squared_error: 0.0470\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0468 - mean_squared_error: 0.0468\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0465 - mean_squared_error: 0.0465\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0463 - mean_squared_error: 0.0463\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0461 - mean_squared_error: 0.0461\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0458 - mean_squared_error: 0.0458\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0456 - mean_squared_error: 0.0456\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0453 - mean_squared_error: 0.0453\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0451 - mean_squared_error: 0.0451\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0448 - mean_squared_error: 0.0448\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0446 - mean_squared_error: 0.0446\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0444 - mean_squared_error: 0.0444\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0442 - mean_squared_error: 0.0442\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0439 - mean_squared_error: 0.0439\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0437 - mean_squared_error: 0.0437\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0435 - mean_squared_error: 0.0435\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0433 - mean_squared_error: 0.0433\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0431 - mean_squared_error: 0.0431\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0428 - mean_squared_error: 0.0428\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0426 - mean_squared_error: 0.0426\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0424 - mean_squared_error: 0.0424\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0422 - mean_squared_error: 0.0422\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0420 - mean_squared_error: 0.0420\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0418 - mean_squared_error: 0.0418\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0416 - mean_squared_error: 0.0416\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0414 - mean_squared_error: 0.0414\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0412 - mean_squared_error: 0.0412\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0410 - mean_squared_error: 0.0410\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0408 - mean_squared_error: 0.0408\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0406 - mean_squared_error: 0.0406\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0404 - mean_squared_error: 0.0404\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0402 - mean_squared_error: 0.0402\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0400 - mean_squared_error: 0.0400\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0398 - mean_squared_error: 0.0398\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0396 - mean_squared_error: 0.0396\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0394 - mean_squared_error: 0.0394\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0392 - mean_squared_error: 0.0392\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0390 - mean_squared_error: 0.0390\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0388 - mean_squared_error: 0.0388\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0387 - mean_squared_error: 0.0387\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0385 - mean_squared_error: 0.0385\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0383 - mean_squared_error: 0.0383\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0381 - mean_squared_error: 0.0381\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0379 - mean_squared_error: 0.0379\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0378 - mean_squared_error: 0.0378\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0376 - mean_squared_error: 0.0376\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0374 - mean_squared_error: 0.0374\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0372 - mean_squared_error: 0.0372\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0371 - mean_squared_error: 0.0371\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0369 - mean_squared_error: 0.0369\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0367 - mean_squared_error: 0.0367\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0365 - mean_squared_error: 0.0365\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0364 - mean_squared_error: 0.0364\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0362 - mean_squared_error: 0.0362\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0361 - mean_squared_error: 0.0361\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0359 - mean_squared_error: 0.0359\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0357 - mean_squared_error: 0.0357\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0356 - mean_squared_error: 0.0356\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0354 - mean_squared_error: 0.0354\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0353 - mean_squared_error: 0.0353\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0351 - mean_squared_error: 0.0351\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0350 - mean_squared_error: 0.0350\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0348 - mean_squared_error: 0.0348\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0347 - mean_squared_error: 0.0347\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0345 - mean_squared_error: 0.0345\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0344 - mean_squared_error: 0.0344\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0342 - mean_squared_error: 0.0342\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0341 - mean_squared_error: 0.0341\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0339 - mean_squared_error: 0.0339\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0338 - mean_squared_error: 0.0338\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0337 - mean_squared_error: 0.0337\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0335 - mean_squared_error: 0.0335\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0334 - mean_squared_error: 0.0334\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0333 - mean_squared_error: 0.0333\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0331 - mean_squared_error: 0.0331\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0330 - mean_squared_error: 0.0330\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0329 - mean_squared_error: 0.0329\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0328 - mean_squared_error: 0.0328\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0327 - mean_squared_error: 0.0327\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0325 - mean_squared_error: 0.0325\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0324 - mean_squared_error: 0.0324\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0323 - mean_squared_error: 0.0323\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0321 - mean_squared_error: 0.0321\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0320 - mean_squared_error: 0.0320\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0319 - mean_squared_error: 0.0319\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0318 - mean_squared_error: 0.0318\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0317 - mean_squared_error: 0.0317\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0316 - mean_squared_error: 0.0316\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0314 - mean_squared_error: 0.0314\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0313 - mean_squared_error: 0.0313\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0312 - mean_squared_error: 0.0312\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0311 - mean_squared_error: 0.0311\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0310 - mean_squared_error: 0.0310\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0309 - mean_squared_error: 0.0309\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0308 - mean_squared_error: 0.0308\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0308 - mean_squared_error: 0.0308\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0307 - mean_squared_error: 0.0307\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0306 - mean_squared_error: 0.0306\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0305 - mean_squared_error: 0.0305\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0305 - mean_squared_error: 0.0305\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0304 - mean_squared_error: 0.0304\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0303 - mean_squared_error: 0.0303\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0302 - mean_squared_error: 0.0302\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0302 - mean_squared_error: 0.0302\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0301 - mean_squared_error: 0.0301\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0300 - mean_squared_error: 0.0300\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0300 - mean_squared_error: 0.0300\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0299 - mean_squared_error: 0.0299\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0299 - mean_squared_error: 0.0299\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0298 - mean_squared_error: 0.0298\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0298 - mean_squared_error: 0.0298\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0297 - mean_squared_error: 0.0297\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0296 - mean_squared_error: 0.0296\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0296 - mean_squared_error: 0.0296\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0295 - mean_squared_error: 0.0295\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0295 - mean_squared_error: 0.0295\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0294 - mean_squared_error: 0.0294\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0294 - mean_squared_error: 0.0294\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0294 - mean_squared_error: 0.0294\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0293 - mean_squared_error: 0.0293\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0293 - mean_squared_error: 0.0293\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0292 - mean_squared_error: 0.0292\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0292 - mean_squared_error: 0.0292\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0291 - mean_squared_error: 0.0291\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0291 - mean_squared_error: 0.0291\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0291 - mean_squared_error: 0.0291\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0290 - mean_squared_error: 0.0290\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0290 - mean_squared_error: 0.0290\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0290 - mean_squared_error: 0.0290\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0289 - mean_squared_error: 0.0289\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0289 - mean_squared_error: 0.0289\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0288 - mean_squared_error: 0.0288\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0288 - mean_squared_error: 0.0288\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0288 - mean_squared_error: 0.0288\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0287 - mean_squared_error: 0.0287\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0287 - mean_squared_error: 0.0287\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0287 - mean_squared_error: 0.0287\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0286 - mean_squared_error: 0.0286\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0286 - mean_squared_error: 0.0286\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0286 - mean_squared_error: 0.0286\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0285 - mean_squared_error: 0.0285\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0285 - mean_squared_error: 0.0285\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0285 - mean_squared_error: 0.0285\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0284 - mean_squared_error: 0.0284\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0284 - mean_squared_error: 0.0284\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0284 - mean_squared_error: 0.0284\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0284 - mean_squared_error: 0.0284\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0283 - mean_squared_error: 0.0283\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0283 - mean_squared_error: 0.0283\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0283 - mean_squared_error: 0.0283\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0282 - mean_squared_error: 0.0282\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0282 - mean_squared_error: 0.0282\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0282 - mean_squared_error: 0.0282\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0281 - mean_squared_error: 0.0281\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0281 - mean_squared_error: 0.0281\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0281 - mean_squared_error: 0.0281\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0280 - mean_squared_error: 0.0280\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0280 - mean_squared_error: 0.0280\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0280 - mean_squared_error: 0.0280\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0279 - mean_squared_error: 0.0279\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0279 - mean_squared_error: 0.0279\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0279 - mean_squared_error: 0.0279\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0278 - mean_squared_error: 0.0278\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0278 - mean_squared_error: 0.0278\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0278 - mean_squared_error: 0.0278\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0277 - mean_squared_error: 0.0277\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0277 - mean_squared_error: 0.0277\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0277 - mean_squared_error: 0.0277\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0276 - mean_squared_error: 0.0276\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0276 - mean_squared_error: 0.0276\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0276 - mean_squared_error: 0.0276\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0275 - mean_squared_error: 0.0275\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0275 - mean_squared_error: 0.0275\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0274 - mean_squared_error: 0.0274\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0274 - mean_squared_error: 0.0274\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0274 - mean_squared_error: 0.0274\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0273 - mean_squared_error: 0.0273\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0273 - mean_squared_error: 0.0273\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0273 - mean_squared_error: 0.0273\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0272 - mean_squared_error: 0.0272\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0272 - mean_squared_error: 0.0272\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0271 - mean_squared_error: 0.0271\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0271 - mean_squared_error: 0.0271\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0270 - mean_squared_error: 0.0270\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0270 - mean_squared_error: 0.0270\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0270 - mean_squared_error: 0.0270\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0269 - mean_squared_error: 0.0269\n",
      "Epoch 298/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0269 - mean_squared_error: 0.0269\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0268 - mean_squared_error: 0.0268\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0268 - mean_squared_error: 0.0268\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0267 - mean_squared_error: 0.0267\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0267 - mean_squared_error: 0.0267\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0266 - mean_squared_error: 0.0266\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0266 - mean_squared_error: 0.0266\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0265 - mean_squared_error: 0.0265\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0265 - mean_squared_error: 0.0265\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0265 - mean_squared_error: 0.0265\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0264 - mean_squared_error: 0.0264\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0264 - mean_squared_error: 0.0264\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0263 - mean_squared_error: 0.0263\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0263 - mean_squared_error: 0.0263\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0262 - mean_squared_error: 0.0262\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0261 - mean_squared_error: 0.0261\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0261 - mean_squared_error: 0.0261\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0260 - mean_squared_error: 0.0260\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0260 - mean_squared_error: 0.0260\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0259 - mean_squared_error: 0.0259\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0259 - mean_squared_error: 0.0259\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0258 - mean_squared_error: 0.0258\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0258 - mean_squared_error: 0.0258\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0257 - mean_squared_error: 0.0257\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0257 - mean_squared_error: 0.0257\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0256 - mean_squared_error: 0.0256\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0255 - mean_squared_error: 0.0255\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0255 - mean_squared_error: 0.0255\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0254 - mean_squared_error: 0.0254\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0254 - mean_squared_error: 0.0254\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0253 - mean_squared_error: 0.0253\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0252 - mean_squared_error: 0.0252\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0252 - mean_squared_error: 0.0252\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0251 - mean_squared_error: 0.0251\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0251 - mean_squared_error: 0.0251\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0250 - mean_squared_error: 0.0250\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0249 - mean_squared_error: 0.0249\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0249 - mean_squared_error: 0.0249\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0248 - mean_squared_error: 0.0248\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0248 - mean_squared_error: 0.0248\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0247 - mean_squared_error: 0.0247\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0246 - mean_squared_error: 0.0246\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0246 - mean_squared_error: 0.0246\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0245 - mean_squared_error: 0.0245\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0244 - mean_squared_error: 0.0244\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0244 - mean_squared_error: 0.0244\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0243 - mean_squared_error: 0.0243\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0242 - mean_squared_error: 0.0242\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0242 - mean_squared_error: 0.0242\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0241 - mean_squared_error: 0.0241\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0240 - mean_squared_error: 0.0240\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0240 - mean_squared_error: 0.0240\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0238 - mean_squared_error: 0.0238\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0237 - mean_squared_error: 0.0237\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0237 - mean_squared_error: 0.0237\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0236 - mean_squared_error: 0.0236\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0235 - mean_squared_error: 0.0235\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0235 - mean_squared_error: 0.0235\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0234 - mean_squared_error: 0.0234\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0233 - mean_squared_error: 0.0233\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0232 - mean_squared_error: 0.0232\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0232 - mean_squared_error: 0.0232\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0231 - mean_squared_error: 0.0231\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0230 - mean_squared_error: 0.0230\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0230 - mean_squared_error: 0.0230\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0229 - mean_squared_error: 0.0229\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0228 - mean_squared_error: 0.0228\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0227 - mean_squared_error: 0.0227\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0227 - mean_squared_error: 0.0227\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0226 - mean_squared_error: 0.0226\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0225 - mean_squared_error: 0.0225\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0224 - mean_squared_error: 0.0224\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0224 - mean_squared_error: 0.0224\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0223 - mean_squared_error: 0.0223\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0222 - mean_squared_error: 0.0222\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0221 - mean_squared_error: 0.0221\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0221 - mean_squared_error: 0.0221\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0220 - mean_squared_error: 0.0220\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0219 - mean_squared_error: 0.0219\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0218 - mean_squared_error: 0.0218\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0217 - mean_squared_error: 0.0217\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0217 - mean_squared_error: 0.0217\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0216 - mean_squared_error: 0.0216\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0215 - mean_squared_error: 0.0215\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0214 - mean_squared_error: 0.0214\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0213 - mean_squared_error: 0.0213\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0213 - mean_squared_error: 0.0213\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0212 - mean_squared_error: 0.0212\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0211 - mean_squared_error: 0.0211\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0210 - mean_squared_error: 0.0210\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0209 - mean_squared_error: 0.0209\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0209 - mean_squared_error: 0.0209\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0208 - mean_squared_error: 0.0208\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0207 - mean_squared_error: 0.0207\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0206 - mean_squared_error: 0.0206\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0205 - mean_squared_error: 0.0205\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0205 - mean_squared_error: 0.0205\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0204 - mean_squared_error: 0.0204\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0203 - mean_squared_error: 0.0203\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0202 - mean_squared_error: 0.0202\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0201 - mean_squared_error: 0.0201\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0200 - mean_squared_error: 0.0200\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0200 - mean_squared_error: 0.0200\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0199 - mean_squared_error: 0.0199\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0198 - mean_squared_error: 0.0198\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0197 - mean_squared_error: 0.0197\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0196 - mean_squared_error: 0.0196\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0195 - mean_squared_error: 0.0195\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0194 - mean_squared_error: 0.0194\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0194 - mean_squared_error: 0.0194\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0193 - mean_squared_error: 0.0193\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0192 - mean_squared_error: 0.0192\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0191 - mean_squared_error: 0.0191\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0190 - mean_squared_error: 0.0190\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0189 - mean_squared_error: 0.0189\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0189 - mean_squared_error: 0.0189\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_squared_error: 0.0188\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0187 - mean_squared_error: 0.0187\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0186 - mean_squared_error: 0.0186\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0185 - mean_squared_error: 0.0185\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0184 - mean_squared_error: 0.0184\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0183 - mean_squared_error: 0.0183\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0183 - mean_squared_error: 0.0183\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0182 - mean_squared_error: 0.0182\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0181 - mean_squared_error: 0.0181\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0180 - mean_squared_error: 0.0180\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0179 - mean_squared_error: 0.0179\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0178 - mean_squared_error: 0.0178\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0178 - mean_squared_error: 0.0178\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0177 - mean_squared_error: 0.0177\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0176 - mean_squared_error: 0.0176\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0175 - mean_squared_error: 0.0175\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0174 - mean_squared_error: 0.0174\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0173 - mean_squared_error: 0.0173\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0173 - mean_squared_error: 0.0173\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0172 - mean_squared_error: 0.0172\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0171 - mean_squared_error: 0.0171\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0170 - mean_squared_error: 0.0170\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0169 - mean_squared_error: 0.0169\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0169 - mean_squared_error: 0.0169\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0168 - mean_squared_error: 0.0168\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0167 - mean_squared_error: 0.0167\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0166 - mean_squared_error: 0.0166\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0165 - mean_squared_error: 0.0165\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0165 - mean_squared_error: 0.0165\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0164 - mean_squared_error: 0.0164\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0163 - mean_squared_error: 0.0163\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0162 - mean_squared_error: 0.0162\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0162 - mean_squared_error: 0.0162\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0161 - mean_squared_error: 0.0161\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0160 - mean_squared_error: 0.0160\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0159 - mean_squared_error: 0.0159\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0159 - mean_squared_error: 0.0159\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0158 - mean_squared_error: 0.0158\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0157 - mean_squared_error: 0.0157\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0156 - mean_squared_error: 0.0156\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0156 - mean_squared_error: 0.0156\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0155 - mean_squared_error: 0.0155\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0154 - mean_squared_error: 0.0154\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0154 - mean_squared_error: 0.0154\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0153 - mean_squared_error: 0.0153\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0152 - mean_squared_error: 0.0152\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0152 - mean_squared_error: 0.0152\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0151 - mean_squared_error: 0.0151\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0150 - mean_squared_error: 0.0150\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0150 - mean_squared_error: 0.0150\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0149 - mean_squared_error: 0.0149\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0149 - mean_squared_error: 0.0149\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0148 - mean_squared_error: 0.0148\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0147 - mean_squared_error: 0.0147\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0147 - mean_squared_error: 0.0147\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0146 - mean_squared_error: 0.0146\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0146 - mean_squared_error: 0.0146\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0145 - mean_squared_error: 0.0145\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0144 - mean_squared_error: 0.0144\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0144 - mean_squared_error: 0.0144\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0143 - mean_squared_error: 0.0143\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0143 - mean_squared_error: 0.0143\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0142 - mean_squared_error: 0.0142\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0142 - mean_squared_error: 0.0142\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0141 - mean_squared_error: 0.0141\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0141 - mean_squared_error: 0.0141\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0138 - mean_squared_error: 0.0138\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0138 - mean_squared_error: 0.0138\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0136 - mean_squared_error: 0.0136\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0136 - mean_squared_error: 0.0136\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0135 - mean_squared_error: 0.0135\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0135 - mean_squared_error: 0.0135\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0134 - mean_squared_error: 0.0134\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0134 - mean_squared_error: 0.0134\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0134 - mean_squared_error: 0.0134\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0133 - mean_squared_error: 0.0133\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0133 - mean_squared_error: 0.0133\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0130 - mean_squared_error: 0.0130\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0130 - mean_squared_error: 0.0130\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0130 - mean_squared_error: 0.0130\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0128 - mean_squared_error: 0.0128\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0128 - mean_squared_error: 0.0128\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0128 - mean_squared_error: 0.0128\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0123 - mean_squared_error: 0.0123\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0119 - mean_squared_error: 0.0119\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0119 - mean_squared_error: 0.0119\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0119 - mean_squared_error: 0.0119\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0119 - mean_squared_error: 0.0119\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0118 - mean_squared_error: 0.0118\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0118 - mean_squared_error: 0.0118\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0118 - mean_squared_error: 0.0118\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0118 - mean_squared_error: 0.0118\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0118 - mean_squared_error: 0.0118\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0117 - mean_squared_error: 0.0117\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0117 - mean_squared_error: 0.0117\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0117 - mean_squared_error: 0.0117\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0117 - mean_squared_error: 0.0117\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0116 - mean_squared_error: 0.0116\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0116 - mean_squared_error: 0.0116\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0116 - mean_squared_error: 0.0116\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0116 - mean_squared_error: 0.0116\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0116 - mean_squared_error: 0.0116\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0115 - mean_squared_error: 0.0115\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0115 - mean_squared_error: 0.0115\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0115 - mean_squared_error: 0.0115\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0115 - mean_squared_error: 0.0115\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0115 - mean_squared_error: 0.0115\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0113 - mean_squared_error: 0.0113\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0113 - mean_squared_error: 0.0113\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0113 - mean_squared_error: 0.0113\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0113 - mean_squared_error: 0.0113\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0113 - mean_squared_error: 0.0113\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0112 - mean_squared_error: 0.0112\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0112 - mean_squared_error: 0.0112\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0112 - mean_squared_error: 0.0112\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0112 - mean_squared_error: 0.0112\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0112 - mean_squared_error: 0.0112\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0112 - mean_squared_error: 0.0112\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0110 - mean_squared_error: 0.0110\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0110 - mean_squared_error: 0.0110\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0110 - mean_squared_error: 0.0110\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0110 - mean_squared_error: 0.0110\n",
      "Epoch 594/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0110 - mean_squared_error: 0.0110\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0109 - mean_squared_error: 0.0109\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0109 - mean_squared_error: 0.0109\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0109 - mean_squared_error: 0.0109\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0109 - mean_squared_error: 0.0109\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0109 - mean_squared_error: 0.0109\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0109 - mean_squared_error: 0.0109\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0105 - mean_squared_error: 0.0105\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0105 - mean_squared_error: 0.0105\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0105 - mean_squared_error: 0.0105\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0105 - mean_squared_error: 0.0105\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0105 - mean_squared_error: 0.0105\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0105 - mean_squared_error: 0.0105\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0103 - mean_squared_error: 0.0103\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0103 - mean_squared_error: 0.0103\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0103 - mean_squared_error: 0.0103\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0103 - mean_squared_error: 0.0103\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0103 - mean_squared_error: 0.0103\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0103 - mean_squared_error: 0.0103\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0103 - mean_squared_error: 0.0103\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0102 - mean_squared_error: 0.0102\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0102 - mean_squared_error: 0.0102\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_squared_error: 0.0102\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0102 - mean_squared_error: 0.0102\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_squared_error: 0.0102\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_squared_error: 0.0102\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0102 - mean_squared_error: 0.0102\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0101 - mean_squared_error: 0.0101\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0101 - mean_squared_error: 0.0101\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0101 - mean_squared_error: 0.0101\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0101 - mean_squared_error: 0.0101\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0101 - mean_squared_error: 0.0101\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0101 - mean_squared_error: 0.0101\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0101 - mean_squared_error: 0.0101\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0099 - mean_squared_error: 0.0099\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0099 - mean_squared_error: 0.0099\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0099 - mean_squared_error: 0.0099\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0099 - mean_squared_error: 0.0099\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0099 - mean_squared_error: 0.0099\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0099 - mean_squared_error: 0.0099\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0099 - mean_squared_error: 0.0099\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0094 - mean_squared_error: 0.0094\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0094 - mean_squared_error: 0.0094\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0094 - mean_squared_error: 0.0094\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0094 - mean_squared_error: 0.0094\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0094 - mean_squared_error: 0.0094\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0094 - mean_squared_error: 0.0094\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0094 - mean_squared_error: 0.0094\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0094 - mean_squared_error: 0.0094\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0091 - mean_squared_error: 0.0091\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0091 - mean_squared_error: 0.0091\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0091 - mean_squared_error: 0.0091\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0091 - mean_squared_error: 0.0091\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0091 - mean_squared_error: 0.0091\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0091 - mean_squared_error: 0.0091\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0091 - mean_squared_error: 0.0091\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0091 - mean_squared_error: 0.0091\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0091 - mean_squared_error: 0.0091\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 965us/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0079 - mean_squared_error: 0.0079\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0079 - mean_squared_error: 0.0079\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0079 - mean_squared_error: 0.0079\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0079 - mean_squared_error: 0.0079\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0079 - mean_squared_error: 0.0079\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0079 - mean_squared_error: 0.0079\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0079 - mean_squared_error: 0.0079\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0079 - mean_squared_error: 0.0079\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0079 - mean_squared_error: 0.0079\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0079 - mean_squared_error: 0.0079\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 890/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0065 - mean_squared_error: 0.0065\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=len(x_train),\n",
    "    epochs=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we see how the neural network's output has (hopefully) improved..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f34d03db370>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train, y_train, label = \"targets\")\n",
    "plt.plot(x_train, model(x_train).numpy(),label=\"model output\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Run the previous 2 cells again to train the network a bit more.  \n",
    "\n",
    "We can see the universal function approximation capability of the neural network in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next we'll view how some of the weights have changed from earlier, by the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1 weights [<tf.Variable 'dense/kernel:0' shape=(1, 10) dtype=float32, numpy=\n",
      "array([[-0.09271087, -0.241206  ,  0.4490061 , -0.3389768 ,  0.25488597,\n",
      "        -0.25145313,  0.08051342,  0.89309347, -0.728286  ,  0.28077978]],\n",
      "      dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=\n",
      "array([ 0.25870937,  0.25994417, -0.23141952,  0.08770128,  0.28791255,\n",
      "        0.20660007,  0.2899449 ,  0.17075583,  0.12587765, -0.04695916],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(\"layer1 weights\",layer1.trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Understanding the Training Objective, and Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These weights have changed - because the training process works by iteratively adjusting the weights to perform gradient descent on the \"loss\" function.  Here we used the Mean Squared Error, so we have minimised\n",
    "$$L=(1/N)\\sum_{k=1}^N (f({x}_k,w)-y_k)^2$$\n",
    "with respect to all of the weights $w$, where $w=$(layer1.traininable_weights, layer2.trainable_weights, layer3.trainable_weights), and where $f$ is the neural network model, and $(x_k, y_k)$ are the $k$th training point's $x$ and (target) $y$ value.\n",
    "\n",
    "We can plot how $L$ decreased over time during training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying the Learning rate\n",
    "- Try the above experiments again with a different learning rate.\n",
    "- I found with learning rate Adam 0.001, I could get the neural output matching the targets almost perfectly.  **Try This**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Saving your network\n",
    "\n",
    "- We can save our final model, and its weights and biases, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mike/.local/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We can then load it back at a later date with..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_neural_network\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.models.load_model('saved_model') # just need to give it a folder name here.\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Further Challenges\n",
    "\n",
    "If you get time today then:\n",
    "\n",
    "- What happens if we put a tanh activation function into the final layer?  Try it?  What problems do we get for learning this particular dataset?  **Answer:**\n",
    "\n",
    "- What will happen to the function approximation capabilities of this network if we increase the number of nodes in each hidden layer?  **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Follow-up Reading\n",
    "\n",
    "- Learn more about the [keras train and evaluate](https://www.tensorflow.org/guide/keras/train_and_evaluate) process.\n",
    "\n",
    "-  For most learning tasks you need a validation set too, and you can use it to check you are not overfitting the data.  See [overfit and underfit](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
